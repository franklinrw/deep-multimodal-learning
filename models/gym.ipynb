{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functions import get_loader, plot_histories, plot_history\n",
    "from ae_functions import train_autoencoder, validate_cae, visualize_latent_space, visualize_reconstruction, get_latent_dataset\n",
    "from ae_models import DeepCAE, DeepBatchCAE, SimpleCAE, SimpleBatchCAE, SimpleCAE_Dropout, SimpleBatchDropoutCAE\n",
    "import torch.nn as nn\n",
    "from mlp_functions import train_mlp, validate_mlp, decision_level_fusion\n",
    "from mlp_models import rawMLP, MLP, dropout_MLP, ImprovedMLP\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU...\n"
     ]
    }
   ],
   "source": [
    "##### CONFIG\n",
    "NUM_EPOCHS = 5\n",
    "LR_RATE = 1e-3\n",
    "BATCH_SIZE = 8\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "DEVICE = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU...\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU...\")\n",
    "\n",
    "BASE_PATH = 'C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/fusion'\n",
    "\n",
    "# Define the tool names and actions\n",
    "TOOL_NAMES = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "ACTIONS = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "\n",
    "# All available object names\n",
    "OBJECTS = ['0_woodenCube', '1_pearToy', '2_yogurtYellowbottle', '3_cowToy', '4_tennisBallYellowGreen',\n",
    "            '5_blackCoinbag', '6_lemonSodaCan', '7_peperoneGreenToy', '8_boxEgg','9_pumpkinToy',\n",
    "            '10_tomatoCan', '11_boxMilk', '12_containerNuts', '13_cornCob', '14_yellowFruitToy',\n",
    "            '15_bottleNailPolisher', '16_boxRealSense', '17_clampOrange', '18_greenRectangleToy', '19_ketchupToy']\n",
    "\n",
    "sensor_color = \"color\"\n",
    "sensor_left = \"icub_left\"\n",
    "sensor_right = \"icub_right\"\n",
    "sensor_depth = \"depthcolormap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, \"training\", batch_size=BATCH_SIZE)\n",
    "val_loader = get_loader(BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, \"validation\", batch_size=BATCH_SIZE)\n",
    "test_loader = get_loader(BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, \"testing\", batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], AVG Loss: 0.6351, AVG PSNR: 8.0480, AVG SSIM: 0.1510\n",
      "Epoch [2/10], AVG Loss: 0.5375, AVG PSNR: 9.3953, AVG SSIM: 0.3520\n",
      "Epoch [3/10], AVG Loss: 0.4707, AVG PSNR: 10.6804, AVG SSIM: 0.5259\n",
      "Epoch [4/10], AVG Loss: 0.4185, AVG PSNR: 11.9835, AVG SSIM: 0.6602\n",
      "Epoch [5/10], AVG Loss: 0.3770, AVG PSNR: 13.2819, AVG SSIM: 0.7566\n",
      "Epoch [6/10], AVG Loss: 0.3437, AVG PSNR: 14.5655, AVG SSIM: 0.8246\n",
      "Epoch [7/10], AVG Loss: 0.3169, AVG PSNR: 15.8367, AVG SSIM: 0.8727\n",
      "Epoch [8/10], AVG Loss: 0.2953, AVG PSNR: 17.0757, AVG SSIM: 0.9064\n",
      "Epoch [9/10], AVG Loss: 0.2777, AVG PSNR: 18.2766, AVG SSIM: 0.9303\n",
      "Epoch [10/10], AVG Loss: 0.2630, AVG PSNR: 19.4788, AVG SSIM: 0.9478\n",
      "Average Validation Loss: 0.2571732569485903\n",
      "Average PSNR: 20.021577807683556\n",
      "Average SSIM: 0.9542404986426908\n"
     ]
    }
   ],
   "source": [
    "# cae_lossfunction = nn.MSELoss()\n",
    "cae_lossfunction = nn.BCELoss()\n",
    "\n",
    "#cae = SimpleCAE(input_channels=3).to(DEVICE)\n",
    "cae = SimpleBatchCAE(input_channels=3).to(DEVICE)\n",
    "#cae = SimpleCAE_Dropout(input_channels=3).to(DEVICE)\n",
    "#cae = SimpleBatchDropoutCAE(input_channels=3, dropout_rate=0.25).to(DEVICE)\n",
    "#cae = DeepCAE(input_channels=3).to(DEVICE)\n",
    "#cae = DeepBatchCAE(input_channels=3).to(DEVICE)\n",
    "\n",
    "optimizer= torch.optim.Adam(cae.parameters(), lr=LR_RATE)\n",
    "# optimizer = torch.optim.SGD(cae.parameters(), lr=LR_RATE, momentum=0.9)\n",
    "# optimizer = torch.optim.AdamW(cae.parameters(), lr=LR_RATE, weight_decay=1e-2)\n",
    "\n",
    "trained_cae, cae_epoch_loss_history = train_autoencoder(cae,\\\n",
    "                                                        train_loader,\\\n",
    "                                                        cae_lossfunction,\\\n",
    "                                                        optimizer,\\\n",
    "                                                        is_depth=False,\\\n",
    "                                                        num_epochs=NUM_EPOCHS,\\\n",
    "                                                        device=DEVICE,\\\n",
    "                                                        visualize=False)\n",
    "\n",
    "avg_val_loss, cae_validation_loss_history = validate_cae(trained_cae,\\\n",
    "                                                        test_loader,\\\n",
    "                                                        cae_lossfunction,\\\n",
    "                                                        is_depth = False,\\\n",
    "                                                        device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot_histories(cae_batch_loss_history, cae_validation_loss_history)\n",
    "# visualize_reconstruction(trained_cae, test_loader, num_samples=2)\n",
    "# visualize_latent_space(trained_cae, test_loader, n_components=2)\n",
    "# # plot_history(mlp_epoch_avg_losses)\n",
    "# # plot_history(mlp_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "weight_name = \"batchnorm/batch_cae_ne5_b8_depth.pth\"\n",
    "torch.save(trained_cae.state_dict(), model_path+weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "weight_name = \"batchnorm/batch_cae_ne5_b8_color.pth\"\n",
    "trained_cae = SimpleBatchCAE().to(DEVICE)\n",
    "trained_cae.load_state_dict(torch.load(model_path+weight_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147456\n"
     ]
    }
   ],
   "source": [
    "# Config MLP\n",
    "mlp_lossfunction = nn.CrossEntropyLoss()  # Loss function\n",
    "output_dim = 4 \n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# Extract features from the train and validation sets\n",
    "train_dataset = get_latent_dataset(trained_cae, test_loader, add_noise=False, is_depth=False, device=DEVICE)\n",
    "val_dataset = get_latent_dataset(trained_cae, val_loader, add_noise=False, is_depth=False, device=DEVICE)\n",
    "\n",
    "# Create DataLoaders for the extracted features\n",
    "mlp_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "mlp_val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize\n",
    "input_dim = train_dataset[:][0].size(1)\n",
    "print(input_dim)\n",
    "# mlp = MLP(input_dim, output_dim).to(DEVICE)\n",
    "# # mlp = ImprovedMLP(input_dim, output_dim).to(DEVICE)\n",
    "# # #mlp = MLP_Dropout(input_dim, output_dim).to(DEVICE)\n",
    "# # #mlp = rawMLP(input_dim, output_dim).to(DEVICE)\n",
    "# mlp_optimizer = torch.optim.Adam(mlp.parameters(), lr=LR_RATE)\n",
    "\n",
    "# # # Train the model\n",
    "# trained_mlp = train_mlp(mlp, mlp_lossfunction, mlp_optimizer, mlp_train_loader, NUM_EPOCHS, DEVICE)\n",
    "\n",
    "# # Validate the model\n",
    "# validate_mlp(trained_mlp, mlp_lossfunction, mlp_val_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "weight_name = \"batchnorm/mlp_ne5_b8_depth_broken.pth\"\n",
    "torch.save(trained_mlp.state_dict(), model_path+weight_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new MLP model with the same architecture\n",
    "mlp_loaded = MLP(input_dim, output_dim)  # Replace 'input_dim' and 'output_dim' with appropriate values\n",
    "mlp_loaded.load_state_dict(torch.load(model_path+weight_name))\n",
    "mlp_loaded = mlp_loaded.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
