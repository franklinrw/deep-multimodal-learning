{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functions import CustomSampler, load_pretrained_mlp, load_pretrained_cae, get_model_predictions, average_fusion_predictions, calculate_classification_report, calculate_fusion_accuracy\n",
    "from ae_functions import get_latent_dataloader\n",
    "from ae_models import DeepCAE, DeepBatchCAE, SimpleCAE, SimpleBatchCAE, SimpleCAE_Dropout, SimpleBatchDropoutCAE\n",
    "from mlp_functions import train_mlp, validate_mlp, decision_level_fusion\n",
    "from mlp_models import rawMLP, MLP, dropout_MLP, ImprovedMLP\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU...\n"
     ]
    }
   ],
   "source": [
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = 147456\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU...\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU...\")\n",
    "\n",
    "# Define the tool names and actions\n",
    "TOOL_NAMES = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "ACTIONS = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "\n",
    "# All available object names\n",
    "OBJECTS = ['0_woodenCube', '1_pearToy', '2_yogurtYellowbottle', '3_cowToy', '4_tennisBallYellowGreen',\n",
    "            '5_blackCoinbag', '6_lemonSodaCan', '7_peperoneGreenToy', '8_boxEgg','9_pumpkinToy',\n",
    "            '10_tomatoCan', '11_boxMilk', '12_containerNuts', '13_cornCob', '14_yellowFruitToy',\n",
    "            '15_bottleNailPolisher', '16_boxRealSense', '17_clampOrange', '18_greenRectangleToy', '19_ketchupToy']\n",
    "\n",
    "BASE_PATH = 'C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/fusion'\n",
    "\n",
    "sensor_color = \"color\"\n",
    "sensor_left = \"icub_left\"\n",
    "sensor_right = \"icub_right\"\n",
    "sensor_depth = \"depthcolormap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "left_to_right       0.91      0.98      0.95       160\n",
      "         pull       0.99      0.89      0.94       160\n",
      "         push       0.94      0.96      0.95       160\n",
      "right_to_left       0.97      0.97      0.97       160\n",
      "\n",
      "     accuracy                           0.95       640\n",
      "    macro avg       0.95      0.95      0.95       640\n",
      " weighted avg       0.95      0.95      0.95       640\n",
      "\n",
      "0.953125\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "cae_color = load_pretrained_cae(SimpleBatchCAE, model_path, \"batchnorm/batch_cae_ne5_b8_color.pth\", DEVICE)\n",
    "cae_left = load_pretrained_cae(SimpleBatchCAE, model_path, \"batchnorm/batch_cae_ne5_b8_left.pth\", DEVICE)\n",
    "cae_right = load_pretrained_cae(SimpleBatchCAE, model_path, \"batchnorm/batch_cae_ne5_b8_right.pth\", DEVICE)\n",
    "\n",
    "# Load MLP models\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "mlp_color = load_pretrained_mlp(MLP, model_path, \"batchnorm/mlp_ne5_b8_color.pth\", DEVICE, input_dim, output_dim)\n",
    "mlp_left = load_pretrained_mlp(MLP, model_path, \"batchnorm/mlp_ne5_b8_left.pth\", DEVICE, input_dim, output_dim)\n",
    "mlp_right = load_pretrained_mlp(MLP, model_path, \"batchnorm/mlp_ne5_b8_right.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [mlp_color, mlp_left, mlp_right]\n",
    "\n",
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"validation\"\n",
    "test_loader_color = get_latent_dataloader(cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left = get_latent_dataloader(cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right = get_latent_dataloader(cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right]\n",
    "\n",
    "# Get predictions\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)]\n",
    "\n",
    "# Combine and average predictions\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.tolist() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "true_labels = [labels.tolist() for _, labels in test_loader_color]\n",
    "accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "calculate_classification_report(predicted_classes_list, true_labels, class_names)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load CAE models\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "\n",
    "# weight_name = \"batchnorm/batch_cae_ne5_b8_color.pth\"\n",
    "# cae_color = SimpleBatchCAE().to(DEVICE)\n",
    "# cae_color.load_state_dict(torch.load(model_path+weight_name))\n",
    "\n",
    "# weight_name = \"batchnorm/batch_cae_ne5_b8_left.pth\"\n",
    "# cae_left = SimpleBatchCAE().to(DEVICE)\n",
    "# cae_left.load_state_dict(torch.load(model_path+weight_name))\n",
    "\n",
    "# weight_name = \"batchnorm/batch_cae_ne5_b8_right.pth\"\n",
    "# cae_right = SimpleBatchCAE().to(DEVICE)\n",
    "# cae_right.load_state_dict(torch.load(model_path+weight_name))\n",
    "\n",
    "# # Load MLP models\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "\n",
    "# weight_name = \"batchnorm/mlp_ne5_b8_color.pth\"\n",
    "# mlp_color = MLP(input_dim, output_dim).to(DEVICE)  # Replace 'input_dim' and 'output_dim' with appropriate values\n",
    "# mlp_color.load_state_dict(torch.load(model_path+weight_name))\n",
    "# mlp_color.eval()\n",
    "\n",
    "# weight_name = \"batchnorm/mlp_ne5_b8_left.pth\"\n",
    "# mlp_left = MLP(input_dim, output_dim).to(DEVICE)  # Replace 'input_dim' and 'output_dim' with appropriate values\n",
    "# mlp_left.load_state_dict(torch.load(model_path+weight_name))\n",
    "# mlp_left.eval()\n",
    "\n",
    "# weight_name = \"batchnorm/mlp_ne5_b8_right.pth\"\n",
    "# mlp_right = MLP(input_dim, output_dim).to(DEVICE)  # Replace 'input_dim' and 'output_dim' with appropriate values\n",
    "# mlp_right.load_state_dict(torch.load(model_path+weight_name))\n",
    "# mlp_right.eval()\n",
    "\n",
    "# models = [mlp_color, mlp_left, mlp_right]\n",
    "\n",
    "# # Get data loaders -> latent dataset loaders\n",
    "# test_loader_color = get_loader(BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, \"testing\", batch_size=BATCH_SIZE)\n",
    "# test_loader_right = get_loader(BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, \"testing\", batch_size=BATCH_SIZE)\n",
    "# test_loader_left = get_loader(BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, \"testing\", batch_size=BATCH_SIZE)\n",
    "\n",
    "# dataset_color = get_latent_dataset(cae_color, test_loader_color, add_noise=False, is_depth=False, device=DEVICE)\n",
    "# test_loader_color = torch.utils.data.DataLoader(dataset_color, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataset_left = get_latent_dataset(cae_left, test_loader_left, add_noise=False, is_depth=False, device=DEVICE)\n",
    "# test_loader_left = torch.utils.data.DataLoader(dataset_left, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataset_right = get_latent_dataset(cae_right, test_loader_right, add_noise=False, is_depth=False, device=DEVICE)\n",
    "# test_loader_right = torch.utils.data.DataLoader(dataset_right, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataloaders = [test_loader_color, test_loader_left, test_loader_right]\n",
    "\n",
    "\n",
    "# model_predictions = []\n",
    "# # Assuming 'models' is a list of your trained models and 'dataloaders' is the corresponding list of dataloaders\n",
    "# for model, dataloader in zip(models, dataloaders):\n",
    "#     predictions = []\n",
    "\n",
    "#     with torch.no_grad():  # No need to calculate gradients\n",
    "#         for inputs, _ in dataloader:  # Labels are not needed for prediction\n",
    "#             inputs = inputs.to(DEVICE)  # Move the input data to the GPU\n",
    "#             outputs = model(inputs)\n",
    "#             # Convert outputs to desired format (e.g., probabilities, class indices)\n",
    "#             predictions.append(outputs)\n",
    "    \n",
    "#     model_predictions.append(predictions)\n",
    "\n",
    "# # Example for averaging probabilities (assuming softmax outputs)\n",
    "# final_predictions = []\n",
    "# for i in range(len(dataloaders[0])):  # Assuming all dataloaders have the same length\n",
    "#     # Average predictions across models for each sample\n",
    "#     avg_prediction = sum(model_predictions[j][i] for j in range(len(models))) / len(models)\n",
    "#     final_predictions.append(avg_prediction)\n",
    "    \n",
    "# predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "\n",
    "# true_labels = {0:[],1:[],2:[]}\n",
    "# for i, dataloader in enumerate(dataloaders):\n",
    "#     for _, labels in dataloader:\n",
    "#         true_labels[i].append(labels.tolist())\n",
    "\n",
    "# # Convert predicted classes to lists if they are tensors\n",
    "# predicted_classes_list = [pred.tolist() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# # Flatten the list of lists for true labels and predicted classes\n",
    "# flattened_true_labels = [label for sublist in true_labels[0] for label in sublist]\n",
    "# flattened_predicted_classes = [pred for sublist in predicted_classes_list for pred in sublist]\n",
    "\n",
    "# # Ensure that the lengths of flattened true labels and predicted classes are the same\n",
    "# assert len(flattened_true_labels) == len(flattened_predicted_classes), \"Mismatch in the number of predictions and true labels\"\n",
    "\n",
    "# # Calculate the number of correct predictions\n",
    "# correct_predictions = sum(pred == true for pred, true in zip(flattened_predicted_classes, flattened_true_labels))\n",
    "\n",
    "# # Calculate total predictions and accuracy\n",
    "# total_predictions = len(flattened_true_labels)\n",
    "# accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
