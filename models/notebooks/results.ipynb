{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from functions import CustomSampler, load_pretrained_mlp, load_pretrained_cae, get_model_predictions, average_fusion_predictions, calculate_classification_report, calculate_fusion_accuracy\n",
    "from ae_functions import get_latent_dataloader\n",
    "from ae_models import improvedCAE, simpleCAE\n",
    "from mlp_functions import train_mlp, validate_mlp, decision_level_fusion\n",
    "from mlp_models import improvedMLP, simpleMLP\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(pred):\n",
    "    batch_pred = []\n",
    "    for batch in pred:\n",
    "        batch_pred.extend(batch.argmax(dim=-1).cpu().numpy())\n",
    "    return batch_pred\n",
    "\n",
    "def unpack_labels(labels):\n",
    "    batch_labels = []\n",
    "    for batch in labels:\n",
    "        batch_labels.extend(batch)\n",
    "    return batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(preds_list, class_names, true_labels, setup, save_dir):\n",
    "    sensor = [\"Color\", \"Icub_left\", \"Icub_right\"]\n",
    "    for s, preds in enumerate(preds_list):\n",
    "        matrix = confusion_matrix(true_labels, preds)\n",
    "\n",
    "        # Reverse the order of class names\n",
    "        class_names_reversed = class_names[::-1]\n",
    "\n",
    "        # Reverse the order of the confusion matrix\n",
    "        matrix_reversed = np.flip(matrix, axis=0)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(matrix_reversed, cmap='Blues')\n",
    "\n",
    "        # Add explicit values to the confusion matrix\n",
    "        for i in range(matrix_reversed.shape[0]):\n",
    "            for j in range(matrix_reversed.shape[1]):\n",
    "                plt.text(j, i, str(matrix_reversed[i, j]), ha='center', va='center', color='orange')\n",
    "\n",
    "        plt.colorbar()\n",
    "        plt.xticks(range(len(class_names)), class_names)  # Set x-axis labels\n",
    "        plt.yticks(range(len(class_names)), class_names_reversed)  # Set y-axis labels\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title(f'Confusion Matrix {setup} For {sensor[s]} Sensor')\n",
    "\n",
    "        # Save the confusion matrix\n",
    "        save_path = os.path.join(save_dir, f'confusion_matrix_{setup}_{sensor[s]}.png')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved confusion matrix for {sensor[s]} sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds_list, true_labels):\n",
    "    accuracies = []\n",
    "    for preds in preds_list:\n",
    "        accuracies.append(accuracy_score(true_labels, preds))\n",
    "    print(\"color: \", accuracies[0], \" left: \", accuracies[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU...\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU...\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU...\")\n",
    "\n",
    "# Define the tool names and actions\n",
    "TOOL_NAMES = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "ACTIONS = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "\n",
    "# All available object names\n",
    "OBJECTS = ['0_woodenCube', '1_pearToy', '2_yogurtYellowbottle', '3_cowToy', '4_tennisBallYellowGreen',\n",
    "            '5_blackCoinbag', '6_lemonSodaCan', '7_peperoneGreenToy', '8_boxEgg','9_pumpkinToy',\n",
    "            '10_tomatoCan', '11_boxMilk', '12_containerNuts', '13_cornCob', '14_yellowFruitToy',\n",
    "            '15_bottleNailPolisher', '16_boxRealSense', '17_clampOrange', '18_greenRectangleToy', '19_ketchupToy']\n",
    "\n",
    "BASE_PATH = 'C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/fusion'\n",
    "\n",
    "sensor_color = \"color\"\n",
    "sensor_left = \"icub_left\"\n",
    "sensor_right = \"icub_right\"\n",
    "sensor_depth = \"depthcolormap\"\n",
    "\n",
    "# # Load CAE models\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "# cae_color = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_color.pth\", DEVICE)\n",
    "# cae_left = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_icub_left.pth\", DEVICE)\n",
    "# cae_right = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_icub_right.pth\", DEVICE)\n",
    "# cae_depth = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_depthcolormap.pth\", DEVICE)\n",
    "\n",
    "# # Load CAE models Improved\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "cae_color = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_color_noise.pth\", DEVICE)\n",
    "cae_left = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_left_noise.pth\", DEVICE)\n",
    "cae_right = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_right_noise.pth\", DEVICE)\n",
    "#cae_depth = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_depthcolormap.pth\", DEVICE)\n",
    "\n",
    "# # Load CAE models Improved\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "# cae_color = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_color_noise.pth\", DEVICE)\n",
    "# cae_left = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_left_noise.pth\", DEVICE)\n",
    "# cae_right = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_right_noise.pth\", DEVICE)\n",
    "# # cae_depth = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_depth.pth\", DEVICE)\n",
    "\n",
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=0, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=0, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "#test_loader_right, size = get_latent_dataloader(cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=0, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "#test_loader_depth, size = get_latent_dataloader(cae_depth, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_depth, set_name, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size                                          \n",
    "\n",
    "# Load MLP models\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "# mlp_color = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_color_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_left = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_icub_left_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_right = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_icub_right_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_depth = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_depthcolormap_action.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "# mlp_color = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_color_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_left = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_left_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_right = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_right_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_depth = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_depthcolormap_action.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "mlp_color = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_color_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "mlp_left = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_left_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "#mlp_right = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_right_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "# mlp_color = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_color.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_left = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_icub_left.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_right = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_icub_right.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_depth = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_depthcolormap.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "# model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "# mlp_color = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_color_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_left = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_left_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_right = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_right_action.pth\", DEVICE, input_dim, output_dim)\n",
    "# mlp_depth = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_depthcolormap_action.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [mlp_color, mlp_left]\n",
    "\n",
    "# Get predictions\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)]\n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "#right = model_predictions[2]\n",
    "#depth = model_predictions[3]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "# class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "#right_preds = get_predictions(right)\n",
    "#depth_preds = get_predictions(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color:  0.209375  left:  0.25\n"
     ]
    }
   ],
   "source": [
    "get_accuracy([color_preds, left_preds], true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for Color sensor\n",
      "Saved confusion matrix for Icub_left sensor\n",
      "Saved confusion matrix for Icub_right sensor\n"
     ]
    }
   ],
   "source": [
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/\"\n",
    "get_confusion_matrix([color_preds, left_preds], class_names, true_labels, \"improvedCAE+improvedMLP+Tool\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
