{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from functions import CustomSampler, load_pretrained_mlp, load_pretrained_cae, get_model_predictions, average_fusion_predictions, calculate_classification_report, calculate_fusion_accuracy\n",
    "from ae_functions import get_latent_dataloader\n",
    "from ae_models import improvedCAE, simpleCAE\n",
    "from mlp_functions import train_mlp, validate_mlp, decision_level_fusion\n",
    "from mlp_models import improvedMLP, simpleMLP\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(pred):\n",
    "    batch_pred = []\n",
    "    for batch in pred:\n",
    "        batch_pred.extend(batch.argmax(dim=-1).cpu().numpy())\n",
    "    return batch_pred\n",
    "\n",
    "def unpack_labels(labels):\n",
    "    batch_labels = []\n",
    "    for batch in labels:\n",
    "        batch_labels.extend(batch)\n",
    "    return batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(preds_list, class_names, true_labels, setup, save_dir):\n",
    "    sensor = [\"Color\", \"Icub_left\", \"Icub_right\", \"Depth\"]\n",
    "    for s, preds in enumerate(preds_list):\n",
    "        matrix = confusion_matrix(true_labels, preds)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))  # Adjust figure size for better readability\n",
    "        plt.imshow(matrix, cmap='Blues')\n",
    "\n",
    "        # Add explicit values to the confusion matrix\n",
    "        for i in range(matrix.shape[0]):\n",
    "            for j in range(matrix.shape[1]):\n",
    "                color = 'white' if matrix[i, j] > matrix.max() / 2 else 'black'  # Contrast color for readability\n",
    "                plt.text(j, i, format(matrix[i, j], 'd'), ha='center', va='center', \n",
    "                        color=color, fontsize=18, weight='bold')  # Adjust font size and add background\n",
    "\n",
    "        plt.xticks(range(len(class_names)), class_names, fontsize=20)  # Rotate x-axis labels for better visibility\n",
    "        plt.yticks(range(len(class_names)), class_names, fontsize=20)\n",
    "        plt.xlabel('Predicted', fontsize=16)  # Increase font size\n",
    "        plt.ylabel('True', fontsize=16)  # Increase font size\n",
    "        plt.title(f'{setup} + {sensor[s]} Sensor', fontsize=20)  # Increase font size\n",
    "\n",
    "        # Move x-axis to the top\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.xaxis.set_label_position('top')\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the confusion matrix\n",
    "        save_path = os.path.join(save_dir, f'confusion_matrix_{setup}_{sensor[s]}.png')\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved confusion matrix for {sensor[s]} sensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_fusion(preds, class_names, true_labels, setup, save_dir):\n",
    "    matrix = confusion_matrix(true_labels, preds)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))  # Adjust figure size for better readability\n",
    "    plt.imshow(matrix, cmap='Blues')\n",
    "\n",
    "    # Add explicit values to the confusion matrix\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            color = 'white' if matrix[i, j] > matrix.max() / 2 else 'black'  # Contrast color for readability\n",
    "            plt.text(j, i, format(matrix[i, j], 'd'), ha='center', va='center', color=color, fontsize=18, weight='bold')  # Adjust font size and add background\n",
    "\n",
    "    plt.xticks(range(len(class_names)), class_names, fontsize=20, weight='bold')  # Rotate x-axis labels for better visibility\n",
    "    plt.yticks(range(len(class_names)), class_names, fontsize=20, weight='bold')\n",
    "    plt.xlabel('Predicted', fontsize=16)  # Increase font size\n",
    "    plt.ylabel('True', fontsize=16)  # Increase font size\n",
    "    plt.title(f'{setup}', fontsize=20)  # Increase font size\n",
    "\n",
    "    # Move x-axis to the top\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the confusion matrix\n",
    "    save_path = os.path.join(save_dir, f'confusion_matrix_{setup}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {setup}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(preds_list, true_labels):\n",
    "    accuracies = []\n",
    "    for preds in preds_list:\n",
    "        accuracies.append(accuracy_score(true_labels, preds))\n",
    "    print(\"color: \", accuracies[0], \" left: \", accuracies[1], \" right: \", accuracies[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU...\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "DEVICE = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU...\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU...\")\n",
    "\n",
    "# Define the tool names and actions\n",
    "TOOL_NAMES = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "ACTIONS = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "\n",
    "# All available object names\n",
    "OBJECTS = ['0_woodenCube', '1_pearToy', '2_yogurtYellowbottle', '3_cowToy', '4_tennisBallYellowGreen',\n",
    "            '5_blackCoinbag', '6_lemonSodaCan', '7_peperoneGreenToy', '8_boxEgg','9_pumpkinToy',\n",
    "            '10_tomatoCan', '11_boxMilk', '12_containerNuts', '13_cornCob', '14_yellowFruitToy',\n",
    "            '15_bottleNailPolisher', '16_boxRealSense', '17_clampOrange', '18_greenRectangleToy', '19_ketchupToy']\n",
    "\n",
    "BASE_PATH = 'C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/fusion'\n",
    "\n",
    "sensor_color = \"color\"\n",
    "sensor_left = \"icub_left\"\n",
    "sensor_right = \"icub_right\"\n",
    "sensor_depth = \"depthcolormap\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load CAE models\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_ae/\"\n",
    "simple_cae_color = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_color.pth\", DEVICE)\n",
    "simple_cae_left = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_icub_left.pth\", DEVICE)\n",
    "simple_cae_right = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_icub_right.pth\", DEVICE)\n",
    "simple_cae_depth = load_pretrained_cae(simpleCAE, model_path, \"simple/simple_cae_ne3_b8_depthcolormap.pth\", DEVICE)\n",
    "\n",
    "# Load CAE models Improved\n",
    "improved_dcae_color = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_color_noise.pth\", DEVICE)\n",
    "improved_dcae_left = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_left_noise.pth\", DEVICE)\n",
    "improved_dcae_right = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_right_noise.pth\", DEVICE)\n",
    "\n",
    "# Load CAE models Improved\n",
    "improved_cae_color = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_color.pth\", DEVICE)\n",
    "improved_cae_left = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_left.pth\", DEVICE)\n",
    "improved_cae_right = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_icub_right.pth\", DEVICE)\n",
    "improved_cae_depth = load_pretrained_cae(improvedCAE, model_path, \"improved/improved_cae_ne3_b8_depthcolormap.pth\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color:  0.9546875  left:  0.7875  right:  0.25\n",
      "Saved confusion matrix for Color sensor\n",
      "Saved confusion matrix for Icub_left sensor\n",
      "Saved confusion matrix for Icub_right sensor\n",
      "Saved confusion matrix for Depth sensor\n",
      "Saved confusion matrix for simpleCAE+simpleMLP+Fusion\n"
     ]
    }
   ],
   "source": [
    "# simpleCAE + simpleMLP\n",
    "\n",
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(simple_cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(simple_cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(simple_cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_depth, size = get_latent_dataloader(simple_cae_depth, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_depth, set_name,labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right, test_loader_depth]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "simple_mlp_color = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_color_action.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_left = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_icub_left_action.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_right = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_icub_right_action.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_depth = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_ne3_b8_depthcolormap_action.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [simple_mlp_color, simple_mlp_left, simple_mlp_right, simple_mlp_depth]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "depth = model_predictions[3]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "depth_preds = get_predictions(depth)  \n",
    "\n",
    "get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds, depth_preds], class_names, true_labels, \"simpleCAE+simpleMLP\", dir)\n",
    "\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "pr = get_predictions(final_predictions)\n",
    "get_confusion_matrix_fusion(pr, class_names, true_labels,\"simpleCAE+simpleMLP+Fusion\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for simpleCAE+improvedMLP+Fusion\n"
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(simple_cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(simple_cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(simple_cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_depth, size = get_latent_dataloader(simple_cae_depth, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_depth, set_name,labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right, test_loader_depth]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "improved_mlp_simple_color = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_color.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_simple_left = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_icub_left.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_simple_right = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_icub_right.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_simple_depth = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_simple_cae_ne3_b8_depthcolormap.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [improved_mlp_simple_color, improved_mlp_simple_left, improved_mlp_simple_right, improved_mlp_simple_depth]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "depth = model_predictions[3]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "# class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "depth_preds = get_predictions(depth)  \n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds, depth_preds], class_names, true_labels, \"simpleCAE+improvedMLP\", dir)\n",
    "\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "pr = get_predictions(final_predictions)\n",
    "get_confusion_matrix_fusion(pr, class_names, true_labels,\"simpleCAE+improvedMLP+Fusion\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for improvedCAE+simpleMLP+Fusion\n"
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(improved_cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(improved_cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(improved_cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_depth, size = get_latent_dataloader(improved_cae_depth, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_depth, set_name,labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right, test_loader_depth]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "simple_mlp_improved_cae_color = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_color_action.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_improved_cae_left = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_left_action.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_improved_cae_right = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_right_action.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_improved_cae_depth = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_depthcolormap_action.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [simple_mlp_improved_cae_color, simple_mlp_improved_cae_left, simple_mlp_improved_cae_right, simple_mlp_improved_cae_depth]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "depth = model_predictions[3]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "depth_preds = get_predictions(depth)  \n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds, depth_preds], class_names, true_labels, \"improvedCAE+simpleMLP\", dir)\n",
    "\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "pr = get_predictions(final_predictions)\n",
    "get_confusion_matrix_fusion(pr, class_names, true_labels,\"improvedCAE+simpleMLP+Fusion\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m set_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m test_loader_color, size \u001b[38;5;241m=\u001b[39m get_latent_dataloader(improved_cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, device\u001b[38;5;241m=\u001b[39mDEVICE, indices\u001b[38;5;241m=\u001b[39mshuffled_indices)\n\u001b[1;32m----> 8\u001b[0m test_loader_left, size \u001b[38;5;241m=\u001b[39m \u001b[43mget_latent_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimproved_cae_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBASE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOBJECTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTOOL_NAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mACTIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffled_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m test_loader_right, size \u001b[38;5;241m=\u001b[39m get_latent_dataloader(improved_cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, device\u001b[38;5;241m=\u001b[39mDEVICE, indices\u001b[38;5;241m=\u001b[39mshuffled_indices)\n\u001b[0;32m     10\u001b[0m test_loader_depth, size \u001b[38;5;241m=\u001b[39m get_latent_dataloader(improved_cae_depth, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_depth, set_name,labelc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, device\u001b[38;5;241m=\u001b[39mDEVICE, indices\u001b[38;5;241m=\u001b[39mshuffled_indices)\n",
      "File \u001b[1;32mc:\\Users\\Frank\\OneDrive\\Bureaublad\\ARC\\deep-multimodal-learning\\models\\notebooks\\..\\ae_functions.py:244\u001b[0m, in \u001b[0;36mget_latent_dataloader\u001b[1;34m(cae_model, base_path, objects, tool_names, actions, sensor, set_name, labelc, shuffle, batch_size, device, indices)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_latent_dataloader\u001b[39m(cae_model, base_path, objects, tool_names, actions, sensor, set_name, labelc, shuffle, batch_size, device, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 244\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_latent_dataset(cae_model, test_loader, label\u001b[38;5;241m=\u001b[39mlabelc, add_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, is_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    246\u001b[0m     size \u001b[38;5;241m=\u001b[39m dataset[:][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Frank\\OneDrive\\Bureaublad\\ARC\\deep-multimodal-learning\\models\\notebooks\\..\\functions.py:96\u001b[0m, in \u001b[0;36mget_loader\u001b[1;34m(base_path, objectnames, toolnames, actions, sensor, set_name, shuffle, batch_size)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loader\u001b[39m(base_path, objectnames, toolnames, actions, sensor, set_name, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjectnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoolnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mdataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39mshuffle)\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loader\n",
      "File \u001b[1;32mc:\\Users\\Frank\\OneDrive\\Bureaublad\\ARC\\deep-multimodal-learning\\models\\notebooks\\..\\functions.py:87\u001b[0m, in \u001b[0;36mget_datasets\u001b[1;34m(base_path, objectnames, toolnames, actions, sensor, set_name)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m             dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m             datasets\u001b[38;5;241m.\u001b[39mappend(dataset)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Return a ConcatDataset instance comprising all the datasets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Frank\\OneDrive\\Bureaublad\\ARC\\deep-multimodal-learning\\models\\notebooks\\..\\functions.py:23\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 23\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_with_labels \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(improved_cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(improved_cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(improved_cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_depth, size = get_latent_dataloader(improved_cae_depth, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_depth, set_name,labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right, test_loader_depth]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "improved_mlp_improved_cae_color = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_color_action.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_left = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_left_action.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_right = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_right_action.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_depth = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_depthcolormap_action.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [improved_mlp_improved_cae_color, improved_mlp_improved_cae_left, improved_mlp_improved_cae_right, improved_mlp_improved_cae_depth]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "depth = model_predictions[3]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "depth_preds = get_predictions(depth)  \n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds, depth_preds], class_names, true_labels, \"improvedCAE+improvedMLP\", dir)\n",
    "\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "pr = get_predictions(final_predictions)\n",
    "get_confusion_matrix_fusion(pr, class_names, true_labels,\"improvedCAE+improvedMLP+Fusion\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for improvedDCAE+simpleMLP+Fusion\n"
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(improved_dcae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(improved_dcae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(improved_dcae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "improved_mlp_improved_cae_color_noise = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_color_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_left_noise = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_left_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_right_noise = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_right_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [improved_mlp_improved_cae_color_noise, improved_mlp_improved_cae_left_noise, improved_mlp_improved_cae_right_noise]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds], class_names, true_labels, \"improvedDCAE+simpleMLP\", dir)\n",
    "\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "pr = get_predictions(final_predictions)\n",
    "get_confusion_matrix_fusion(pr, class_names, true_labels,\"improvedDCAE+simpleMLP+Fusion\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for improvedDCAE+improvedMLP+Fusion\n"
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(improved_dcae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(improved_dcae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(improved_dcae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "improved_mlp_improved_cae_color_noise = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_color_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_left_noise = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_left_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_right_noise = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_right_noise.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [improved_mlp_improved_cae_color_noise, improved_mlp_improved_cae_left_noise, improved_mlp_improved_cae_right_noise]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds], class_names, true_labels, \"improvedDCAE+improvedMLP\", dir)\n",
    "\n",
    "final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# Convert to predicted classes\n",
    "predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "pr = get_predictions(final_predictions)\n",
    "get_confusion_matrix_fusion(pr, class_names, true_labels,\"improvedDCAE+improvedMLP+Fusion\", dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for Color sensor\n",
      "Saved confusion matrix for Icub_left sensor\n",
      "Saved confusion matrix for Icub_right sensor\n"
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(improved_dcae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(improved_dcae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(improved_dcae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "simple_mlp_improved_cae_color_tool = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_color_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_improved_cae_left_tool = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_left_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "simple_mlp_improved_cae_right_tool = load_pretrained_mlp(simpleMLP, model_path, \"simple/simple_mlp_improved_cae_ne3_b8_icub_right_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [simple_mlp_improved_cae_color_tool, simple_mlp_improved_cae_left_tool, simple_mlp_improved_cae_right_tool]\n",
    "\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds], class_names, true_labels, \"improvedCAE+simpleMLP+Tool\", dir)\n",
    "\n",
    "# final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# # Convert to predicted classes\n",
    "# predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "# predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# # accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# # print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "# dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "# pr = get_predictions(final_predictions)\n",
    "# get_confusion_matrix_fusion(pr, class_names, true_labels,\"improvedCAE+simpleMLP+Tool\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for Color sensor\n",
      "Saved confusion matrix for Icub_left sensor\n",
      "Saved confusion matrix for Icub_right sensor\n"
     ]
    }
   ],
   "source": [
    "# Assuming the datasets for all sensors are the same size\n",
    "dataset_size = 640  # Replace with the actual size of your dataset\n",
    "shuffled_indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Get dataloaders\n",
    "set_name = \"Testing\"\n",
    "test_loader_color, size = get_latent_dataloader(improved_cae_color, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_color, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_left, size = get_latent_dataloader(improved_cae_left, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_left, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "test_loader_right, size = get_latent_dataloader(improved_cae_right, BASE_PATH, OBJECTS, TOOL_NAMES, ACTIONS, sensor_right, set_name, labelc=1, shuffle=False, batch_size=BATCH_SIZE, device=DEVICE, indices=shuffled_indices)\n",
    "\n",
    "dataloaders = [test_loader_color, test_loader_left, test_loader_right]\n",
    "\n",
    "##### CONFIG\n",
    "output_dim = 4\n",
    "input_dim = size\n",
    "\n",
    "model_path = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/weights_mlp/\"\n",
    "improved_mlp_improved_cae_color_tool = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_color_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_left_tool = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_left_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "improved_mlp_improved_cae_right_tool = load_pretrained_mlp(improvedMLP, model_path, \"simple/improved_mlp_improved_cae_ne3_b8_icub_right_tool.pth\", DEVICE, input_dim, output_dim)\n",
    "\n",
    "models = [improved_mlp_improved_cae_color_tool, improved_mlp_improved_cae_left_tool, improved_mlp_improved_cae_right_tool]\n",
    "model_predictions = [get_model_predictions(model, dataloader, DEVICE) for model, dataloader in zip(models, dataloaders)] \n",
    "\n",
    "color = model_predictions[0]\n",
    "left = model_predictions[1]\n",
    "right = model_predictions[2]\n",
    "\n",
    "# Gather true labels and calculate accuracy\n",
    "class_names = ['left_to_right', 'pull', 'push', 'right_to_left']\n",
    "#class_names = ['hook', 'ruler', 'spatula', 'sshot']\n",
    "true_labels = [labels.cpu().numpy() for _, labels in test_loader_color]\n",
    "true_labels = unpack_labels(true_labels)\n",
    "\n",
    "color_preds = get_predictions(color)\n",
    "left_preds = get_predictions(left)\n",
    "right_preds = get_predictions(right)\n",
    "\n",
    "# get_accuracy([color_preds, left_preds, right_preds], true_labels)\n",
    "\n",
    "dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "get_confusion_matrix([color_preds, left_preds, right_preds], class_names, true_labels, \"improvedCAE+improvedMLP+Tool\", dir)\n",
    "\n",
    "# final_predictions = average_fusion_predictions(model_predictions)\n",
    "\n",
    "# # Convert to predicted classes\n",
    "# predicted_classes = [pred.argmax(dim=-1) for pred in final_predictions]\n",
    "# predicted_classes_list = [pred.cpu().numpy() if torch.is_tensor(pred) else pred for pred in predicted_classes]\n",
    "\n",
    "# # accuracy = calculate_fusion_accuracy(predicted_classes_list, true_labels)\n",
    "# # print(f\"Fusion accuracy: {accuracy}\")\n",
    "\n",
    "# dir = \"C:/Users/Frank/OneDrive/Bureaublad/ARC/deep-multimodal-learning/models/runs/results/matrixes/correct/\"\n",
    "# pr = get_predictions(final_predictions)\n",
    "# get_confusion_matrix_fusion(pr, class_names, true_labels,\"improvedCAE+simpleMLP+Tool\", dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
